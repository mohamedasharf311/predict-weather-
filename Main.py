# ğŸŒ¡ï¸ Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LSTM ÙÙŠ PyTorch
# -----------------------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# 1ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ© (Ø¨Ø¯ÙŠÙ„Ø© Ø¹Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©)
np.random.seed(0)
dates = pd.date_range("2020-01-01", periods=500)
temperature = 25 + np.sin(np.linspace(0, 50, 500)) * 10 + np.random.randn(500)
humidity = 50 + np.random.randn(500) * 5
co2 = 400 + np.random.randn(500) * 20

df = pd.DataFrame({
    'Date': dates,
    'Temperature': temperature,
    'Humidity': humidity,
    'CO2': co2
})

# 2ï¸âƒ£ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Normalization)
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['Temperature', 'Humidity', 'CO2']])

# 3ï¸âƒ£ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¨Ø­ ØªØ³Ù„Ø³Ù„Ø§Øª Ø²Ù…Ù†ÙŠØ©
def create_sequences(data, seq_length):
    X, Y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        Y.append(data[i+seq_length, 0])  # Ø§Ù„Ù‡Ø¯Ù: Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©
    return np.array(X), np.array(Y)

seq_length = 30  # 30 ÙŠÙˆÙ…
X, y = create_sequences(scaled_data, seq_length)

# 4ï¸âƒ£ ØªÙ‚Ø³ÙŠÙ… Train/Test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

X_train = torch.tensor(X_train, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)
y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)

# 5ï¸âƒ£ Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ LSTM
class WeatherLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(WeatherLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    def forward(self, x):
        out, _ = self.lstm(x)
        out = out[:, -1, :]  # Ø¢Ø®Ø± Ø®Ø·ÙˆØ© Ø²Ù…Ù†ÙŠØ©
        out = self.fc(out)
        return out

input_size = 3   # Temp, Humidity, CO2
hidden_size = 50
num_layers = 2
output_size = 1

model = WeatherLSTM(input_size, hidden_size, num_layers, output_size)

# 6ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© ÙˆØ§Ù„Ù…ÙØ­Ø³Ù‘Ù†
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 7ï¸âƒ£ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    outputs = model(X_train)
    loss = criterion(outputs, y_train)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (epoch+1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}")

# 8ï¸âƒ£ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
model.eval()
with torch.no_grad():
    predicted = model(X_test)
    loss = criterion(predicted, y_test)
    print(f"\nTest Loss: {loss.item():.6f}")

# 9ï¸âƒ£ Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
predicted_np = predicted.numpy()
y_test_np = y_test.numpy()

plt.figure(figsize=(10,5))
plt.plot(y_test_np, label='Actual Temperature')
plt.plot(predicted_np, label='Predicted Temperature')
plt.legend()
plt.title('Actual vs Predicted Temperature')
plt.show()

# ğŸ”Ÿ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© (Forecasting)
def forecast_future(model, data, seq_length, days_ahead):
    model.eval()
    last_seq = data[-seq_length:]
    preds = []
    for _ in range(days_ahead):
        seq_tensor = torch.tensor(last_seq[np.newaxis, :, :], dtype=torch.float32)
        with torch.no_grad():
            pred = model(seq_tensor).numpy()
        preds.append(pred[0][0])
        # Ù†Ø¶ÙŠÙ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙˆÙ†Ø­Ø°Ù Ø£Ù‚Ø¯Ù… ÙŠÙˆÙ…
        new_row = np.array([[pred[0][0], last_seq[-1,1], last_seq[-1,2]]])
        last_seq = np.vstack((last_seq[1:], new_row))
    return np.array(preds)

future_preds = forecast_future(model, scaled_data, seq_length=30, days_ahead=7)
print("\nğŸŒ¤ï¸ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø© (Ù‚ÙŠÙ… Ù…ÙØ·Ø¨Ù‘Ø¹Ø©):", future_preds)

# Ø¹ÙƒØ³ Ø§Ù„ØªØ·Ø¨ÙŠØ¹ (Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)
dummy = np.zeros((len(future_preds), 3))
dummy[:,0] = future_preds
future_real = scaler.inverse_transform(dummy)[:,0]
print("ğŸŒ¡ï¸ ØªÙˆÙ‚Ø¹Ø§Øª Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©:", future_real)
